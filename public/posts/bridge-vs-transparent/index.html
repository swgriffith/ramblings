<!doctype html>
<html lang="en-us">
  <head>
    <title>AKS Networking Overview - Network Policy Impact on Bridge Mode vs. Transparent // Steve Griffith</title>
    <meta charset="utf-8" />
    <meta name="generator" content="Hugo 0.75.1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="author" content="Steve Griffth" />
    <meta name="description" content="" />
    <link rel="stylesheet" href="https://www.stevegriffith.nyc/css/main.min.88e7083eff65effb7485b6e6f38d10afbec25093a6fac42d734ce9024d3defbd.css" />

    
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-129005800-1', 'auto');
	
	ga('send', 'pageview');
}
</script>

    <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="AKS Networking Overview - Network Policy Impact on Bridge Mode vs. Transparent"/>
<meta name="twitter:description" content="Overview In our Azure CNI and Kubenet overviews, we assumed no network policy is deployed on our cluster. When you enable network policy there are a few fundamental changes that are probably worth calling out. I&rsquo;m going to focus on Calico network policy in AKS, which is implemented using open source Calico.
Azure CNI If we take a look at the &lsquo;Technical Deep Dive&rsquo; doc for Azure CNI we see that when you implement network policy on a cluster there is one fundamental change."/>
<meta name="twitter:site" content="@SteveGriffith"/>

    <meta property="og:title" content="AKS Networking Overview - Network Policy Impact on Bridge Mode vs. Transparent" />
<meta property="og:description" content="Overview In our Azure CNI and Kubenet overviews, we assumed no network policy is deployed on our cluster. When you enable network policy there are a few fundamental changes that are probably worth calling out. I&rsquo;m going to focus on Calico network policy in AKS, which is implemented using open source Calico.
Azure CNI If we take a look at the &lsquo;Technical Deep Dive&rsquo; doc for Azure CNI we see that when you implement network policy on a cluster there is one fundamental change." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://www.stevegriffith.nyc/posts/bridge-vs-transparent/" />
<meta property="article:published_time" content="2020-11-11T13:56:01-05:00" />
<meta property="article:modified_time" content="2020-11-11T13:56:01-05:00" />


  </head>
  <body>
    <header class="app-header">
      <a href="https://www.stevegriffith.nyc/"><img class="app-header-avatar" src="/images/me.jpg" alt="Steve Griffth" /></a>
      <h1>Steve Griffith</h1>
      <p>Microsoft Cloud Native Global Black Belt. This is my personal blog, so opinions are my own.</p>
      <div class="app-header-social">
        
      </div>
    </header>
    <main class="app-container">
      
  <article class="post">
    <header class="post-header">
      <h1 class ="post-title">AKS Networking Overview - Network Policy Impact on Bridge Mode vs. Transparent</h1>
      <div class="post-meta">
        <div>
          <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-calendar">
  <title>calendar</title>
  <rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line>
</svg>
          Nov 11, 2020
        </div>
        <div>
          <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-clock">
  <title>clock</title>
  <circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline>
</svg>
          6 min read
        </div><div>
          <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-tag">
  <title>tag</title>
  <path d="M20.59 13.41l-7.17 7.17a2 2 0 0 1-2.83 0L2 12V2h10l8.59 8.59a2 2 0 0 1 0 2.82z"></path><line x1="7" y1="7" x2="7" y2="7"></line>
</svg>
          <a class="tag" href="https://www.stevegriffith.nyc/tags/azure/">azure</a><a class="tag" href="https://www.stevegriffith.nyc/tags/kubernetes/">kubernetes</a><a class="tag" href="https://www.stevegriffith.nyc/tags/networking/">networking</a><a class="tag" href="https://www.stevegriffith.nyc/tags/kubenet/">kubenet</a><a class="tag" href="https://www.stevegriffith.nyc/tags/cni/">cni</a><a class="tag" href="https://www.stevegriffith.nyc/tags/aks/">aks</a><a class="tag" href="https://www.stevegriffith.nyc/tags/bridge/">bridge</a><a class="tag" href="https://www.stevegriffith.nyc/tags/transparent/">transparent</a></div></div>
    </header>
    <div class="post-content">
      <h2 id="overview">Overview</h2>
<p>In our <a href="../aks-networking-part1">Azure CNI</a> and <a href="../aks-networking-part1">Kubenet</a> overviews, we assumed no network policy is deployed on our cluster. When you enable network policy there are a few fundamental changes that are probably worth calling out. I&rsquo;m going to focus on Calico network policy in AKS, which is implemented using open source Calico.</p>
<h2 id="azure-cni">Azure CNI</h2>
<p>If we take a look at the <a href="https://azure.microsoft.com/en-us/blog/integrating-azure-cni-and-calico-a-technical-deep-dive/">&lsquo;Technical Deep Dive&rsquo;</a> doc for Azure CNI we see that when you implement network policy on a cluster there is one fundamental change. We move from &lsquo;bridge mode&rsquo; to &lsquo;transparent mode&rsquo; networking. What does that actually mean? Well, we can see it very quickly and easily by running either the kubenet or azure cni deployments we already talked about, setting the &lsquo;&ndash;network-policy calico&rsquo; flag and then running through the same analysis we&rsquo;ve already shown in <a href="../aks-networking-part1">part1</a> and <a href="../aks-networking-part2">part2</a> of our networking overview.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash"><span style="color:#75715e"># We&#39;ll re-use the RG and LOC, so lets set those</span>
RG<span style="color:#f92672">=</span>NetworkLab
LOC<span style="color:#f92672">=</span>eastus

<span style="color:#75715e"># Get the Azure CNI Subnet ID</span>
AZURECNI_SUBNET_ID<span style="color:#f92672">=</span><span style="color:#66d9ef">$(</span>az network vnet show -g $RG -n aksvnet -o tsv --query <span style="color:#e6db74">&#34;subnets[?name==&#39;azurecni&#39;].id&#34;</span><span style="color:#66d9ef">)</span>

<span style="color:#75715e"># Create the same Azure CNI cluster, but with the Calico network plugin</span>
az aks create <span style="color:#ae81ff">\
</span><span style="color:#ae81ff"></span>-g $RG <span style="color:#ae81ff">\
</span><span style="color:#ae81ff"></span>-n azurecni-cluster <span style="color:#ae81ff">\
</span><span style="color:#ae81ff"></span>--network-plugin azure <span style="color:#ae81ff">\
</span><span style="color:#ae81ff"></span>--network-policy calico <span style="color:#ae81ff">\
</span><span style="color:#ae81ff"></span>--vnet-subnet-id $AZURECNI_SUBNET_ID <span style="color:#ae81ff">\
</span><span style="color:#ae81ff"></span>--service-cidr <span style="color:#e6db74">&#34;10.200.0.0/16&#34;</span> <span style="color:#ae81ff">\
</span><span style="color:#ae81ff"></span>--dns-service-ip <span style="color:#e6db74">&#34;10.200.0.10&#34;</span> <span style="color:#ae81ff">\
</span><span style="color:#ae81ff"></span>--enable-managed-identity

<span style="color:#75715e"># Get the deployment manifest</span>
wget https://raw.githubusercontent.com/swgriffith/azure-guides/master/networking-overview/nginx.yaml

<span style="color:#75715e"># Deploy 3 Nginx Pods across 3 nodes</span>
kubectl apply -f nginx.yaml

<span style="color:#75715e"># View the Services and pods</span>
kubectl get svc
kubectl get pods -o wide --sort-by<span style="color:#f92672">=</span>.spec.nodeName <span style="color:#75715e"># Sorted by node name</span>
</code></pre></div><p>Now lets run through the network stack. Again, you&rsquo;ll need to set up ssh access to the node. See part1 or part2 for details.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash"><span style="color:#75715e"># Get the process id for our nginx deployment</span>
docker inspect 0b7c7a46ade1|grep Pid
            <span style="color:#e6db74">&#34;Pid&#34;</span>: 16315,
            <span style="color:#e6db74">&#34;PidMode&#34;</span>: <span style="color:#e6db74">&#34;&#34;</span>,
            <span style="color:#e6db74">&#34;PidsLimit&#34;</span>: null,

<span style="color:#75715e"># Get the pod interface</span>
sudo nsenter -t <span style="color:#ae81ff">16315</span> -n ip addr
1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu <span style="color:#ae81ff">65536</span> qdisc noqueue state UNKNOWN group default qlen <span style="color:#ae81ff">1000</span>
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
15: eth0@if16: &lt;BROADCAST,UP,LOWER_UP&gt; mtu <span style="color:#ae81ff">1500</span> qdisc noqueue state UP group default qlen <span style="color:#ae81ff">1000</span>
    link/ether e6:82:2e:aa:77:ff brd ff:ff:ff:ff:ff:ff link-netnsid <span style="color:#ae81ff">0</span>
    inet 10.220.2.21/24 scope global eth0

<span style="color:#75715e"># Get the host interfaces (abbreviated)</span>
ip addr
1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu <span style="color:#ae81ff">65536</span> qdisc noqueue state UNKNOWN group default qlen <span style="color:#ae81ff">1000</span>
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host
       valid_lft forever preferred_lft forever
2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu <span style="color:#ae81ff">1500</span> qdisc mq state UP group default qlen <span style="color:#ae81ff">1000</span>
    link/ether 00:0d:3a:9c:96:47 brd ff:ff:ff:ff:ff:ff
    inet 10.220.2.4/24 brd 10.220.2.255 scope global eth0
       valid_lft forever preferred_lft forever
    inet6 fe80::20d:3aff:fe9c:9647/64 scope link
       valid_lft forever preferred_lft forever
.
.
.
16: azv33ac2d062ec@if15: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu <span style="color:#ae81ff">1500</span> qdisc noqueue state UP group default qlen <span style="color:#ae81ff">1000</span>
    link/ether 92:81:10:67:e0:26 brd ff:ff:ff:ff:ff:ff link-netnsid <span style="color:#ae81ff">4</span>
    inet6 fe80::9081:10ff:fe67:e026/64 scope link
       valid_lft forever preferred_lft forever
</code></pre></div><p>Notice that we dont have a reference to the &lsquo;azure0&rsquo; bridge that we had in our Azure CNI walk through. Now lets check out the bridge networks and routes.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">sudo apt update
sudo apt install bridge-utils

<span style="color:#75715e"># Check the bridge networks on the host</span>
brctl show
bridge name bridge id           STP enabled interfaces
docker0     8000.0242107e030e   no

<span style="color:#75715e"># Check out the routes on the host</span>
route -n
Kernel IP routing table
Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
0.0.0.0         10.220.2.1      0.0.0.0         UG    <span style="color:#ae81ff">0</span>      <span style="color:#ae81ff">0</span>        <span style="color:#ae81ff">0</span> eth0
10.220.2.0      0.0.0.0         255.255.255.0   U     <span style="color:#ae81ff">0</span>      <span style="color:#ae81ff">0</span>        <span style="color:#ae81ff">0</span> eth0
10.220.2.8      0.0.0.0         255.255.255.255 UH    <span style="color:#ae81ff">0</span>      <span style="color:#ae81ff">0</span>        <span style="color:#ae81ff">0</span> azv590e0427f9b
10.220.2.10     0.0.0.0         255.255.255.255 UH    <span style="color:#ae81ff">0</span>      <span style="color:#ae81ff">0</span>        <span style="color:#ae81ff">0</span> azv5638516250a
10.220.2.16     0.0.0.0         255.255.255.255 UH    <span style="color:#ae81ff">0</span>      <span style="color:#ae81ff">0</span>        <span style="color:#ae81ff">0</span> azvc6db35c2bf7
10.220.2.21     0.0.0.0         255.255.255.255 UH    <span style="color:#ae81ff">0</span>      <span style="color:#ae81ff">0</span>        <span style="color:#ae81ff">0</span> azv33ac2d062ec
10.220.2.28     0.0.0.0         255.255.255.255 UH    <span style="color:#ae81ff">0</span>      <span style="color:#ae81ff">0</span>        <span style="color:#ae81ff">0</span> azva2bb7836522
168.63.129.16   10.220.2.1      255.255.255.255 UGH   <span style="color:#ae81ff">0</span>      <span style="color:#ae81ff">0</span>        <span style="color:#ae81ff">0</span> eth0
169.254.169.254 10.220.2.1      255.255.255.255 UGH   <span style="color:#ae81ff">0</span>      <span style="color:#ae81ff">0</span>        <span style="color:#ae81ff">0</span> eth0
172.17.0.0      0.0.0.0         255.255.0.0     U     <span style="color:#ae81ff">0</span>      <span style="color:#ae81ff">0</span>        <span style="color:#ae81ff">0</span> docker0

</code></pre></div><p>So you should be able to see the difference pretty quickly. First of all, we don&rsquo;t have any bridge networks, other than the docker bridge. So no &lsquo;azure0&rsquo;. On the flip side, we have far more routes. Specifically, we have a route for EVERY interface, including our &lsquo;azv*&rsquo; veth interfaces.</p>
<h3 id="kubenet">Kubenet</h3>
<p>Rather than running through the full setup again, I&rsquo;ll just show you the output of the same set of commands on a kubenet cluster I created with Calico for network policy. Lets check out the interfaces, bridges and routes.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash"><span style="color:#75715e"># Check out the pod interface</span>
sudo nsenter -t <span style="color:#ae81ff">30064</span> -n ip addr
1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu <span style="color:#ae81ff">65536</span> qdisc noqueue state UNKNOWN group default qlen <span style="color:#ae81ff">1000</span>
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
3: eth0@if15: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu <span style="color:#ae81ff">1500</span> qdisc noqueue state UP group default
    link/ether be:26:02:27:b2:cd brd ff:ff:ff:ff:ff:ff link-netnsid <span style="color:#ae81ff">0</span>
    inet 10.244.0.10/32 scope global eth0
       valid_lft forever preferred_lft forever


<span style="color:#75715e"># Check the host interfaces (abbreviated)</span>
ip addr
1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu <span style="color:#ae81ff">65536</span> qdisc noqueue state UNKNOWN group default qlen <span style="color:#ae81ff">1000</span>
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host
       valid_lft forever preferred_lft forever
2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu <span style="color:#ae81ff">1500</span> qdisc mq state UP group default qlen <span style="color:#ae81ff">1000</span>
    link/ether 00:0d:3a:9c:3c:c1 brd ff:ff:ff:ff:ff:ff
    inet 10.240.0.4/16 brd 10.240.255.255 scope global eth0
       valid_lft forever preferred_lft forever
    inet6 fe80::20d:3aff:fe9c:3cc1/64 scope link
       valid_lft forever preferred_lft forever
3: enP1279s1: &lt;BROADCAST,MULTICAST,SLAVE,UP,LOWER_UP&gt; mtu <span style="color:#ae81ff">1500</span> qdisc mq master eth0 state UP group default qlen <span style="color:#ae81ff">1000</span>
    link/ether 00:0d:3a:9c:3c:c1 brd ff:ff:ff:ff:ff:ff
4: docker0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu <span style="color:#ae81ff">1500</span> qdisc noqueue state DOWN group default
    link/ether 02:42:98:e2:19:c6 brd ff:ff:ff:ff:ff:ff
    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0
       valid_lft forever preferred_lft forever
.
.
.
15: cali4cd5cd7d78e@if3: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu <span style="color:#ae81ff">1500</span> qdisc noqueue state UP group default
    link/ether ee:ee:ee:ee:ee:ee brd ff:ff:ff:ff:ff:ff link-netnsid <span style="color:#ae81ff">8</span>
    inet6 fe80::ecee:eeff:feee:eeee/64 scope link
       valid_lft forever preferred_lft forever

<span style="color:#75715e"># Look at the bridge networks</span>
brctl show
bridge name bridge id           STP enabled interfaces
docker0     8000.024298e219c6   no

<span style="color:#75715e"># And finally the routes</span>
route -n
Kernel IP routing table
Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
0.0.0.0         10.240.0.1      0.0.0.0         UG    <span style="color:#ae81ff">0</span>      <span style="color:#ae81ff">0</span>        <span style="color:#ae81ff">0</span> eth0
10.240.0.0      0.0.0.0         255.255.0.0     U     <span style="color:#ae81ff">0</span>      <span style="color:#ae81ff">0</span>        <span style="color:#ae81ff">0</span> eth0
10.244.0.2      0.0.0.0         255.255.255.255 UH    <span style="color:#ae81ff">0</span>      <span style="color:#ae81ff">0</span>        <span style="color:#ae81ff">0</span> cali16fcf5898b5
10.244.0.3      0.0.0.0         255.255.255.255 UH    <span style="color:#ae81ff">0</span>      <span style="color:#ae81ff">0</span>        <span style="color:#ae81ff">0</span> calidb3c3076a20
10.244.0.4      0.0.0.0         255.255.255.255 UH    <span style="color:#ae81ff">0</span>      <span style="color:#ae81ff">0</span>        <span style="color:#ae81ff">0</span> calie303d952cb6
10.244.0.5      0.0.0.0         255.255.255.255 UH    <span style="color:#ae81ff">0</span>      <span style="color:#ae81ff">0</span>        <span style="color:#ae81ff">0</span> calia13e3da9825
10.244.0.6      0.0.0.0         255.255.255.255 UH    <span style="color:#ae81ff">0</span>      <span style="color:#ae81ff">0</span>        <span style="color:#ae81ff">0</span> cali0b8d4f989c0
10.244.0.7      0.0.0.0         255.255.255.255 UH    <span style="color:#ae81ff">0</span>      <span style="color:#ae81ff">0</span>        <span style="color:#ae81ff">0</span> calid51803d5b2f
10.244.0.8      0.0.0.0         255.255.255.255 UH    <span style="color:#ae81ff">0</span>      <span style="color:#ae81ff">0</span>        <span style="color:#ae81ff">0</span> cali84427e61d61
10.244.0.9      0.0.0.0         255.255.255.255 UH    <span style="color:#ae81ff">0</span>      <span style="color:#ae81ff">0</span>        <span style="color:#ae81ff">0</span> calidc7b59b68d8
10.244.0.10     0.0.0.0         255.255.255.255 UH    <span style="color:#ae81ff">0</span>      <span style="color:#ae81ff">0</span>        <span style="color:#ae81ff">0</span> cali4cd5cd7d78e
168.63.129.16   10.240.0.1      255.255.255.255 UGH   <span style="color:#ae81ff">0</span>      <span style="color:#ae81ff">0</span>        <span style="color:#ae81ff">0</span> eth0
169.254.169.254 10.240.0.1      255.255.255.255 UGH   <span style="color:#ae81ff">0</span>      <span style="color:#ae81ff">0</span>        <span style="color:#ae81ff">0</span> eth0
172.17.0.0      0.0.0.0         255.255.0.0     U     <span style="color:#ae81ff">0</span>      <span style="color:#ae81ff">0</span>        <span style="color:#ae81ff">0</span> docker0
</code></pre></div><p>As you can see, once we introduce network policy, we lose the bridge networks and get a bunch of routes added. For kubenet you can also see that our virtual ethernet adapters name changes in kubenet from &lsquo;veth*&rsquo; to &lsquo;calic*&rsquo;, which is an indication of Calico taking over the provisioning of those interfaces.</p>
<h3 id="conclusion">Conclusion</h3>
<p>So across both Kubenet and Azure CNI, once you implement network policy we transition from &lsquo;Bridge Mode&rsquo; to &lsquo;Transparent mode&rsquo;. Based on what we&rsquo;ve seen above this essentially translates to the removal of the bridge network (cbr0 or azure0) and the introduction of routes directly on the host to control the packet flow.</p>
<h3 id="references">References</h3>
<ul>
<li><a href="https://azure.microsoft.com/en-us/blog/integrating-azure-cni-and-calico-a-technical-deep-dive/">Azure CNI Technical Deep Dive</a></li>
</ul>

    </div>
    <div class="post-footer">
      
    </div>
  </article>

    </main>
  </body>
</html>
